{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Tool\n",
    "\n",
    "#### Use Deploy_GR_Global_Test to test unverified models for global growth rates\n",
    "###### Be sure to establish paths where models are stored & where settled models should be stored\n",
    "\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python Libraries\n",
    "import numpy as np\n",
    "import jax      # PIP JAX install - Search for the windows [cpu] version\n",
    "import jaxlib\n",
    "import jax.numpy as jnp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import pandas as pd\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from pathlib import Path\n",
    "import scipy.stats as stats\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Figure Parameters Reset to default\n",
    "def fig_reset():\n",
    "    style.use('default')  # Clear any custom styles that might have been applied\n",
    "    plt.close('all')  # Clear any active figures\n",
    "    plt.set_cmap('viridis')  # Reset default colormaps\n",
    "    plt.rcParams.update(plt.rcParamsDefault)  # Clear any manually set default figure or axes properties\n",
    "    plt.ioff()  # Reset interactive mode\n",
    "    mpl.rcdefaults()  # Reset all rcParams to default values\n",
    "    mpl.rcParams.update(mpl.rcParamsDefault)  # Additional resets for completeness\n",
    "\n",
    "fig_reset() # Reset MATPLOTLIB parameters to default\n",
    "\n",
    "# Colors\n",
    "color_in = 'red'\n",
    "color_mid = 'green'\n",
    "color_out = 'blue'\n",
    "color_by_num = ['crimson', 'orange', 'goldenrod', 'green', 'skyblue', 'darkorchid']\n",
    "simple_color = ['red', 'orange', 'yellow', 'green', 'blue', 'orchid']\n",
    "\n",
    "# Color pallette\n",
    "α = .5\n",
    "ß = 0.25\n",
    "line_width = 1.5\n",
    "full_line_sty = [':', '--', '-', '-.']\n",
    "full_marker_pal = ['o','x','^','s','P','H','*']\n",
    "full_color_pal = ['red', 'orange', 'gold', 'green', 'b', 'darkorchid', 'chocolate', 'deeppink', 'cyan', 'darkcyan', 'black']\n",
    "full_color_pal_disk = ['dimgrey', 'b', 'limegreen', 'firebrick', 'gold', 'orchid', 'chocolate', 'deeppink', 'cyan', 'darkcyan', 'black']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Details Imports\n",
    "\n",
    "Can be used to import a single model by using {variant}_Import\n",
    "\n",
    "Can target all settled models using Deploy_{variant}_Import\n",
    "\n",
    "###### Recommend using Fort_50 as polyout has an error when logging the boundaries for the star and torus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single - Fort.50 import - Pandas Dataframe\n",
    "def Fort_50_Import(target_folder, Transpose):\n",
    "    # Import Fort.50 data\n",
    "    colnames=['col1', 'col2', 'col3', 'col4']\n",
    "    data_raw = pd.read_csv(target_folder / \"fort.50\", names=colnames, header=None, sep='\\s+')\n",
    "    \n",
    "    # Function to remove colons from string values\n",
    "    def remove_colon(x):\n",
    "        if isinstance(x, str):\n",
    "            return x.replace(':', '')\n",
    "        else:\n",
    "            return x\n",
    "    # Remove colons from the first & thrid columns\n",
    "    data_raw[colnames[0]] = data_raw[colnames[0]].apply(lambda x: remove_colon(x) if isinstance(x, str) else x)\n",
    "    data_raw[colnames[2]] = data_raw[colnames[2]].apply(lambda x: remove_colon(x) if isinstance(x, str) else x)\n",
    "    # Clean up row 70 & 71 data name compressed into col1, shifting data into col2\n",
    "    data_raw.loc[70,colnames[0]] = 'drho_min/ro'\n",
    "    data_raw.loc[71,colnames[0]] = 'W_min/ro'\n",
    "    data_raw.loc[70,colnames[1]] = data_raw.loc[70,colnames[2]]\n",
    "    data_raw.loc[71,colnames[1]] = data_raw.loc[71,colnames[2]]\n",
    "    # Fix entry 72\n",
    "    row_72_key = data_raw.loc[72, colnames[2]]\n",
    "    row_72_value = data_raw.loc[72, colnames[3]]\n",
    "    # new row of data\n",
    "    new_data_72 = {colnames[0]: [row_72_key],\n",
    "                colnames[1]: [row_72_value]}\n",
    "    # turn new row data into a dataframe\n",
    "    new_row_72 = pd.DataFrame(new_data_72)\n",
    "    # concatenate the new dataframe to the data set\n",
    "    data_raw = pd.concat([data_raw, new_row_72], ignore_index=True)\n",
    "    # Fix jin,jout to individual entries, concat to dataframe\n",
    "    data_jd_in_value = data_raw.loc[4, colnames[1]]\n",
    "    data_jd_out_value = data_raw.loc[4, colnames[2]]\n",
    "    # new row of data\n",
    "    new_data_jd_in = {colnames[0]: ['jd_in'],\n",
    "                colnames[1]: [data_jd_in_value]}\n",
    "    new_data_jd_out = {colnames[0]: ['jd_out'],\n",
    "                colnames[1]: [data_jd_out_value]}\n",
    "    # turn new row data into a dataframe\n",
    "    new_row_jd_in = pd.DataFrame(new_data_jd_in)\n",
    "    # concatenate the new dataframe to the data set\n",
    "    data_raw = pd.concat([data_raw, new_row_jd_in], ignore_index=True)\n",
    "    # Repeat for jd_out\n",
    "    new_row_jd_out = pd.DataFrame(new_data_jd_out)\n",
    "    data_raw = pd.concat([data_raw, new_row_jd_out], ignore_index=True)\n",
    "    # Fix jstar,kstar overwriting jd_in,jd_out tuble in line 4\n",
    "    data_raw.loc[3,colnames[0]] = 'jstar'\n",
    "    data_raw.loc[4,colnames[0]] = 'kstar'\n",
    "    data_raw.loc[4,colnames[1]] = data_raw.loc[3,colnames[2]]\n",
    "    # Delete extra columns of data\n",
    "    data_raw = data_raw.drop(colnames[3], axis=1)\n",
    "    data_raw = data_raw.drop(colnames[2], axis=1)\n",
    "    # Add disk mode\n",
    "    m_value = re.search(r\"m(\\d+)\", target_folder.name)\n",
    "    m_number = int(m_value.group(1)) if m_value else None\n",
    "    df_disk_m = {colnames[0]: ['model_m'],\n",
    "            colnames[1]: [m_number]}\n",
    "    # turn new row data into a dataframe\n",
    "    new_row_disk_m = pd.DataFrame(df_disk_m)\n",
    "    # concatenate the new dataframe to the data set\n",
    "    df_raw = pd.concat([data_raw, new_row_disk_m], ignore_index=True)\n",
    "    # Rewrite df headers\n",
    "    df_raw.rename(columns={'col1': 'Key', 'col2': 'Value'}, inplace=True)\n",
    "    if Transpose:\n",
    "        # Transpose the DataFrame\n",
    "        df_raw = data_raw.T\n",
    "        # Reset the index\n",
    "        df_raw.reset_index(inplace=True, drop=True)\n",
    "        # Set the first row as column headers\n",
    "        df_raw.columns = df_raw.iloc[0]\n",
    "        # Drop the first row\n",
    "        df_clean = df_raw.drop(0)\n",
    "    else:\n",
    "        # Processing complete\n",
    "        df_clean = df_raw\n",
    "    return(df_clean)\n",
    "\n",
    "def Deploy_Fort_50_Import(Transpose):\n",
    "    settled_models_path = Path(\"..\", \"Data_Galactic_Formation\", \"Models\", \"Settled_Models\").resolve()\n",
    "\n",
    "    # For loop that deploys plotting the phase of the perterbation and W\n",
    "    for target_folder in settled_models_path.iterdir():\n",
    "        # Verify only directories are targeted\n",
    "        if not target_folder.is_dir():\n",
    "            continue  # Skip if not a directory\n",
    "\n",
    "        # Verify target model contains required files fort.22 & fort.23\n",
    "        if not (target_folder / \"fort.50\").exists():\n",
    "            print(f\"Warning: {target_folder.name} is missing fort.50\")\n",
    "            continue  # Skip this folder if fort.22 or fort.23 is missing\n",
    "      \n",
    "        df_50 = Fort_50_Import(target_folder=target_folder, Transpose=Transpose)\n",
    "    \n",
    "    return(df_50)\n",
    "\n",
    "# # Test Fort.50 import\n",
    "# df = Deploy_Fort_50_Import(Transpose=False)\n",
    "# print(df)\n",
    "\n",
    "# Single - Polyout import - for equilibrium\n",
    "def Polyout_Import(target_folder, Transpose):\n",
    "    # Import polyout\n",
    "    colnames = [\"Parameter\", \"Value\", \"Extra\"]\n",
    "    data_raw = pd.read_csv(target_folder / \"polyout\", sep=r'\\s*:\\s*|\\s{2,}', names=colnames, engine='python', skipinitialspace=True)\n",
    "    # Remove leading and trailing whitespace from the 'Parameter' column\n",
    "    data_raw['Parameter'] = data_raw['Parameter'].str.strip()\n",
    "    # Convert numeric columns to numbers\n",
    "    data_raw['Value'] = data_raw['Value'].apply(pd.to_numeric, errors='coerce')\n",
    "    # Fix Line 7 t/|w|\n",
    "    split_key = data_raw.loc[7, colnames[0]]\n",
    "    split_value = data_raw.loc[7, colnames[2]]\n",
    "    data_raw.loc[7, colnames[0]] = \"T/|W|_star\"\n",
    "    # new row of data\n",
    "    new_data = {colnames[0]: \"T/|W|_disk\",\n",
    "                colnames[1]: [split_value]}\n",
    "    # turn new row data into a dataframe\n",
    "    new_row = pd.DataFrame(new_data)\n",
    "    # concatenate the new dataframe to the data set\n",
    "    data_raw = pd.concat([data_raw, new_row], ignore_index=True)\n",
    "    # Fix Line 8 Virial\n",
    "    split_key = data_raw.loc[8, colnames[0]]\n",
    "    split_value = data_raw.loc[8, colnames[2]]\n",
    "    # new row of data\n",
    "    new_data = {colnames[0]: \"Virial_Error_2\",\n",
    "                colnames[1]: [split_value]}\n",
    "    # turn new row data into a dataframe\n",
    "    new_row = pd.DataFrame(new_data)\n",
    "    # concatenate the new dataframe to the data set\n",
    "    data_raw = pd.concat([data_raw, new_row], ignore_index=True)\n",
    "    # Add disk mode\n",
    "    m_value = re.search(r\"m(\\d+)\", target_folder.name)\n",
    "    m_number = int(m_value.group(1)) if m_value else None\n",
    "    new_data = {colnames[0]: \"disk_mode\",\n",
    "                colnames[1]: [m_number]}\n",
    "    # turn new row data into a dataframe\n",
    "    new_row = pd.DataFrame(new_data)\n",
    "    # concatenate the new dataframe to the data set\n",
    "    data_raw = pd.concat([data_raw, new_row], ignore_index=True)\n",
    "    # Delete extra columns of data\n",
    "    data_raw = data_raw.drop(colnames[2], axis=1)\n",
    "    # Convert values to numbers\n",
    "    numeric_cols = ['Value']\n",
    "    data_raw[numeric_cols] = data_raw[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    data_raw[numeric_cols] = data_raw[numeric_cols].astype(float)\n",
    "    if Transpose:\n",
    "        # Transpose the DataFrame\n",
    "        data_raw = data_raw.T\n",
    "        # Reset the index\n",
    "        data_raw.reset_index(inplace=True, drop=True)\n",
    "        # Set the first row as column headers\n",
    "        data_raw.columns = data_raw.iloc[0]\n",
    "        # Drop the first row\n",
    "        data_clean = data_raw.drop(0)\n",
    "    else:\n",
    "        data_clean = data_raw\n",
    "    return(data_clean)\n",
    "\n",
    "def Deploy_Polyout_Import(Transpose):\n",
    "    settled_models_path = Path(\"..\", \"Data_Galactic_Formation\", \"Models\", \"Settled_Models\").resolve()\n",
    "\n",
    "    # For loop that deploys plotting the phase of the perterbation and W\n",
    "    for target_folder in settled_models_path.iterdir():\n",
    "        # Verify only directories are targeted\n",
    "        if not target_folder.is_dir():\n",
    "            continue  # Skip if not a directory\n",
    "\n",
    "        # Verify target model contains required files fort.22 & fort.23\n",
    "        if not (target_folder / \"polyout\").exists():\n",
    "            print(f\"Warning: {target_folder.name} is missing polyout\")\n",
    "            continue  # Skip this folder if fort.22 or fort.23 is missing\n",
    "      \n",
    "        df_polyout = Polyout_Import(target_folder=target_folder, Transpose=Transpose)\n",
    "    \n",
    "    return(df_polyout)\n",
    "\n",
    "# # Test polyout import\n",
    "# df = Deploy_Polyout_Import(Transpose=False)\n",
    "# df.to_csvTest_polyout.csv\", index=False)\n",
    "# print(df)(\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Growth Rate Settled Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command used inside Growth_Rate_Slope_Test to check if the Star and Disk growth rates are settled and agree with each other globally\n",
    "def check_slope_agreement(test_slope, threshold, screen_view):  # test_slope: system's growth rates, threshold: max allowed % difference for agreement, screen_view: print values on screen if True\n",
    "    # Separate Disk and Star slopes\n",
    "    D_slopes = {k: v for k, v in test_slope.items() if k.startswith(\"D_\")}\n",
    "    S_slopes = {k: v for k, v in test_slope.items() if k.startswith(\"S_\")}\n",
    "\n",
    "    # Compute the averages\n",
    "    avg_D = np.mean(list(D_slopes.values()))        # Disk average\n",
    "    avg_S = np.mean(list(S_slopes.values()))        # Star average\n",
    "    avg_Sys = np.mean(list(test_slope.values()))    # System average\n",
    "    Sys_diff = (abs((avg_D - avg_S) / avg_Sys))     # Difference % between Star & Disk\n",
    "    if screen_view:\n",
    "        # print('--- Average Growth Rates ---')\n",
    "        print(f\"Disk: {avg_D:.4f}, Star: {avg_S:.4f}, Global \\u03C9: {avg_Sys:.4f}\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Set initial Star and Disk agreement status\n",
    "    D_status = False\n",
    "    S_status = False\n",
    "    Sys_status = False\n",
    "\n",
    "    # Function to check agreement within a group\n",
    "    def check_internal_agreement(group, avg, screen_view):\n",
    "        for k, v in group.items():\n",
    "            diff = abs((v - avg) / avg)  # Relative difference\n",
    "            status = \"AGREE\" if diff <= threshold else \"DISAGREE\"\n",
    "            if screen_view:\n",
    "                print(f\"{k}: {v:.8f} | Diff: {diff:.3%} -> {status}\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    # Check if all slopes in Disk agree within threshold\n",
    "    if screen_view:\n",
    "        print(\"\\n--- Disk Growth Rate Agreement Check ---\")\n",
    "    else:\n",
    "        pass\n",
    "    check_internal_agreement(group=D_slopes, avg=avg_D, screen_view=screen_view)\n",
    "    if all(abs((v - avg_D) / avg_D) <= threshold for v in D_slopes.values()):\n",
    "        D_status = True  # Set to True if all slopes agree\n",
    "        if screen_view:\n",
    "            print(\"Disk Settled\")\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        if screen_view:\n",
    "            print('Disk NOT Settled')\n",
    "        else:\n",
    "            pass\n",
    "        pass\n",
    "    \n",
    "    # Check if all slopes in Star agree within threshold\n",
    "    if screen_view:\n",
    "        print(\"\\n--- Star Growth Rate Agreement Check ---\")\n",
    "    else:\n",
    "        pass\n",
    "    check_internal_agreement(group=S_slopes, avg=avg_S, screen_view=screen_view)\n",
    "    if all(abs((v - avg_S) / avg_S) <= threshold for v in S_slopes.values()):\n",
    "        S_status = True  # Set to True if all slopes agree\n",
    "        if screen_view:\n",
    "            print(\"Star Settled\")\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        if screen_view:\n",
    "            print('Star NOT Settled')\n",
    "        else:\n",
    "            pass\n",
    "        pass\n",
    "        \n",
    "    # Check if System agrees within threshold\n",
    "    if screen_view:\n",
    "        print(\"\\n--- System Agreement Check ---\")\n",
    "    else:\n",
    "        pass\n",
    "    if D_status == True and S_status == True:\n",
    "        # Compare Disk and Star to check if they agree\n",
    "        if Sys_diff <= threshold:\n",
    "            Sys_status = True\n",
    "            if screen_view:\n",
    "                print(f\"System Difference: {Sys_diff:.2%} -> System Settled Check: {Sys_status}\")\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            if screen_view:\n",
    "                print('System NOT Settled, Star & Disk Settled but do NOT agree')\n",
    "                print('Model needs further time evolution')\n",
    "            else:\n",
    "                pass\n",
    "            pass\n",
    "    else:\n",
    "        if screen_view:\n",
    "            print('System NOT Settled, Star or Disk do not agree')\n",
    "            print('Model needs further time evolution')\n",
    "        else:\n",
    "            pass\n",
    "        pass\n",
    "    if screen_view:\n",
    "        print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return(Sys_status)\n",
    "\n",
    "# Deploys Growth Rate Gobal Agreement test for a single model\n",
    "def Growth_Rate_Slope_Test(MIRP_rng, threshold, screen_view, target_folder, graph, save_graph): # Uses linear regression to build a list of slopes for the Star and Disk, MIRP_rng sets the amount of MIRPS to test from the end of the dataset\n",
    "    # Column titles, Star is from fort.22, Disk is from fort.23\n",
    "    col_name_1 = ['MIRP', 'S_gr_inner_amp', 'S_gr_inner_phase', 'S_gr_middle_amp', 'S_gr_middle_phase', 'S_gr_outer_amp', 'S_gr_outer_phase']\n",
    "    col_name_2 = ['MIRP', 'D_gr_inner_amp', 'D_gr_inner_phase', 'D_gr_middle_amp', 'D_gr_middle_phase', 'D_gr_outer_amp', 'D_gr_outer_phase']\n",
    "\n",
    "    # Clear any previous dataframe info cashed\n",
    "    df1 = None\n",
    "    df2 = None\n",
    "    \n",
    "    # Load data\n",
    "    df1 = pd.read_csv(target_folder / \"fort.22\", names=col_name_1, header=None, sep='\\s+')\n",
    "    df2 = pd.read_csv(target_folder / \"fort.23\", names=col_name_2, header=None, sep='\\s+')\n",
    "\n",
    "    # Merge the dataframes on the 'MIRP' column\n",
    "    df = pd.merge(df1, df2, on=\"MIRP\", suffixes=('_disk', '_star'))\n",
    "\n",
    "    # Drop all columns that end with 'phase'\n",
    "    df = df.drop(columns=df.filter(regex='phase$').columns)\n",
    "\n",
    "    # Ensure that MIRP is numeric\n",
    "    df[\"MIRP\"] = pd.to_numeric(df[\"MIRP\"], errors=\"coerce\")\n",
    "\n",
    "    # Define the range for regression\n",
    "    MIRP_range = MIRP_rng\n",
    "    last_MIRP = df['MIRP'].iloc[-1]\n",
    "    MIRP_threshold = last_MIRP - MIRP_range\n",
    "\n",
    "    # Filter the data for the MIRP time range\n",
    "    df_subset = df[df['MIRP'] >= MIRP_threshold]\n",
    "\n",
    "    # List of columns to process\n",
    "    Settle_Test_Columns = ['D_gr_inner_amp', 'D_gr_middle_amp', 'D_gr_outer_amp', \n",
    "            'S_gr_inner_amp', 'S_gr_middle_amp', 'S_gr_outer_amp']\n",
    "    \n",
    "    # Store slopes for each column\n",
    "    slopes = {}\n",
    "\n",
    "    # Graphing Growth Rates (True/False)\n",
    "    if graph:\n",
    "        plt.figure(figsize=(8, 6))  # Create figure\n",
    "        colors = simple_color   # Select color palette\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Loop through each column and perform regression\n",
    "    for idx, column in enumerate(Settle_Test_Columns):\n",
    "        # Apply log transformation to the y-axis\n",
    "        df_subset = df_subset.copy()  # Avoid SettingWithCopyWarning\n",
    "        df_subset[f'log_{column}'] = np.log10(df_subset[column])\n",
    "\n",
    "        # Perform linear regression\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(df_subset['MIRP'], df_subset[f'log_{column}'])\n",
    "        \n",
    "        # Store the slope in the dictionary\n",
    "        slopes[column] = slope\n",
    "\n",
    "        # Deploy graphing color palette\n",
    "        if graph:\n",
    "            # Apply log transformation to the y-axis for the whole dataset\n",
    "            df = df.copy()  # Avoid SettingWithCopyWarning\n",
    "            df[f'log_{column}'] = np.log10(df[column])\n",
    "            color = colors[idx]  # Get the color from the list\n",
    "            # Plot the original data (log-transformed)\n",
    "            plt.scatter(df['MIRP'], df[f'log_{column}'], label=f'Data ({column}): Slope {slope:.3f}', alpha=0.6, color=color, s=5)\n",
    "\n",
    "            # Plot the regression line\n",
    "            regression_line = slope * df['MIRP'] + intercept\n",
    "            plt.plot(df['MIRP'], regression_line, label=None, color='black', linestyle='--', linewidth=.8)\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    if graph:\n",
    "        # Adding labels and title\n",
    "        plt.xlabel('MIRP')\n",
    "        plt.ylabel(r'log($\\omega$ Amplitude)')\n",
    "        plt.title(r'Linear Regression of log($\\omega$ Amplitude) vs. MIRP')\n",
    "\n",
    "        # Displaying the legend outside of the plot\n",
    "        plt.legend(loc='upper left', bbox_to_anchor=(1, 1), borderaxespad=0.1)\n",
    "\n",
    "        # Save the figure before displaying\n",
    "        if save_graph:\n",
    "            save_path = target_folder / f\"Growth_Rate_Regression_{target_folder.name}.png\"\n",
    "            plt.savefig(save_path, dpi=600, bbox_inches='tight')\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    # Test the slopes for agreement (agree=settled)\n",
    "    model_status = check_slope_agreement(test_slope=slopes, threshold=threshold, screen_view=screen_view)\n",
    "    print(f'Model: {target_folder.name}  |  Settled: {model_status}')\n",
    "    return(model_status)\n",
    "\n",
    "# Test run for the Growth_Rate_Slope_Test Global Agreement\n",
    "# Growth_Rate_Slope_Test(MIRP_rng=1.0, threshold=0.0025, screen_view=False, target_folder=Path(\"\").resolve(), graph=False, save_graph=False)\n",
    "\n",
    "\n",
    "# Deploy Growth_Rate_Slope_Test for Global Agreement for all Unverified Models\n",
    "def Deploy_GR_Global_Test(MIRP_rng, threshold, screen_view, graph, save_graph): # Set target path for 'Unverified_Models' & 'Settled_Models'\n",
    "    # Establish directory paths\n",
    "    print(\"--- Global Growth Rate Test using Linear Regression ---\")\n",
    "        # Location of results .xls file\n",
    "    base_models_path = Path(\"..\", \"Data_Galactic_Formation\", \"Models\").resolve()\n",
    "        # Unverified_Models - target folder for models to be tested if global growth rates have settled into mode\n",
    "    unverified_models_path = Path(\"..\", \"Data_Galactic_Formation\", \"Models\", \"Unverified_Models\").resolve()\n",
    "        # Settled_Models - target folder for Globally Settled models verified to be Settled into Global Growth Rate Mode\n",
    "    settled_models_path = Path(\"..\", \"Data_Galactic_Formation\", \"Models\", \"Settled_Models\").resolve()\n",
    "\n",
    "    # Ensure target directories exist before the loop starts\n",
    "        # Creates new directory if none exist. If directory already exists this line skips\n",
    "    unverified_models_path.mkdir(parents=True, exist_ok=True)\n",
    "    settled_models_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create lists of Unsettled, Settled, or Errored models\n",
    "    settled_model_list = []\n",
    "    unsettled_model_list = []\n",
    "    errored_model_list = []\n",
    "    \n",
    "    # Test each model in Unverified_Models folder for Global Growth Rate\n",
    "        # Moves settled models into Settled_Model folder, leaves unsettled models and adds to a list for HPC restart, errors are compiled into list\n",
    "    for target_folder in unverified_models_path.iterdir():\n",
    "        # Verify only directories are targeted\n",
    "        if not target_folder.is_dir():\n",
    "            continue  # Skip if not a directory\n",
    "\n",
    "        # Verify target model contains required files fort.22 & fort.23\n",
    "        if not (target_folder / \"fort.22\").exists() or not (target_folder / \"fort.23\").exists():\n",
    "            if screen_view:\n",
    "                print(f\"Warning: {target_folder.name} is missing fort.22 or fort.23\")\n",
    "            errored_model_list.append([target_folder.name, \"Error: Missing required files\"])  # Append to error list\n",
    "            continue  # Skip this folder if fort.22 or fort.23 is missing\n",
    "\n",
    "        # Deploy and Sort models based on Global Growth Rate test results\n",
    "        GR_model_status = Growth_Rate_Slope_Test(MIRP_rng=MIRP_rng, threshold=threshold, screen_view=screen_view, target_folder=target_folder, graph=graph, save_graph=save_graph)\n",
    "        if screen_view:\n",
    "            print(f\"\\nTesting Growth Rate: {target_folder.name}\")\n",
    "            print(f\"{target_folder.name} | Model settled into mode: {GR_model_status}\")\n",
    "            print('Regression completed, Growth Rates established')\n",
    "        if GR_model_status:\n",
    "            # Move verified settled models into Settled_Models folder with New/Updated status\n",
    "            dest_folder = settled_models_path / target_folder.name\n",
    "            model_status = \"Settled: New\" if not dest_folder.exists() else \"Settled: Updated\"\n",
    "            shutil.move(str(target_folder), str(dest_folder))\n",
    "            settled_model_list.append([target_folder.name, model_status])  # Append to settled list\n",
    "            if screen_view:\n",
    "                print(f\"settled model {target_folder.name} added to list and moved\")\n",
    "        else:\n",
    "            unsettled_model_list.append([target_folder.name, \"Unsettled\"])  # Append to unsettled list\n",
    "            if screen_view:\n",
    "                print(f\"unsettled model {target_folder.name} added to list\")\n",
    "        \n",
    "    # Create Results DataFrame and concatenate tested models\n",
    "    df_settled_model = pd.DataFrame(settled_model_list, columns=[\"Model\", \"Status\"])\n",
    "    df_unsettled_model = pd.DataFrame(unsettled_model_list, columns=[\"Model\", \"Status\"])\n",
    "    df_errored_model = pd.DataFrame(errored_model_list, columns=[\"Model\", \"Status\"])\n",
    "    df_results = pd.concat([df for df in [df_settled_model, df_unsettled_model, df_errored_model] if not df.empty], ignore_index=True)\n",
    "    \n",
    "    # Save DataFrame as an .xls file\n",
    "    results_file = base_models_path / \"model_status_results.xls\"\n",
    "    df_results.to_excel(results_file, index=False)\n",
    "\n",
    "# Test Run of Deploy_GR_Global_Test\n",
    "# Deploy_GR_Global_Test(MIRP_rng=2.0, threshold=0.0025, screen_view=False, graph=False, save_graph=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using linstar.f to identify how the program writes fort.** files to store ρ phase and W phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Phase_Plot(target_folder, m_val, j_s, j_in, j_out, save_graph, view_graph):\n",
    "    # column names from fort.** files (ref linstar.f)\n",
    "    col_name_pert_phase =['phase5','rnorm(j)','ph180','ph90','ph270']\n",
    "    col_name_W_phase = ['wphase','rnorm(j)','wph180','wph90','wph270']\n",
    "\n",
    "    # import dataframes\n",
    "    phase_pert_df = pd.read_csv(target_folder / \"fort.53\", names=col_name_pert_phase, header=None, sep='\\s+')\n",
    "    phase_W_df = pd.read_csv(target_folder / \"fort.63\", names=col_name_W_phase, header=None, sep='\\s+')\n",
    "    \n",
    "    # Keep only the first two columns\n",
    "    phase_pert_df = phase_pert_df[['rnorm(j)', 'phase5']]\n",
    "    phase_W_df = phase_W_df[['rnorm(j)', 'wphase']]\n",
    "\n",
    "    # Add additional phase shifts dependant on m_value > 1\n",
    "    if m_val > 1:\n",
    "        for i in range(m_val-1):\n",
    "            shift_val = 360/m_val\n",
    "            phase_pert_df[f'phase_shift_pert_{i+1}'] = phase_pert_df['phase5'] + (shift_val * (i+1))\n",
    "            phase_W_df[f'phase_shift_W_{i+1}'] = phase_W_df['wphase'] + (shift_val * (i+1))\n",
    "        \n",
    "    # Graphing Phases\n",
    "    fig, ax = plt.subplots(figsize=(8, 6), subplot_kw={'projection': 'polar'})  # Create polar figure\n",
    "\n",
    "    # Import Fort.50 details for plotting values\n",
    "    df_50 = Fort_50_Import(target_folder=target_folder, Transpose=True)\n",
    "    theta = np.linspace(0, 2*np.pi, 300)  # Full circle in radians\n",
    "\n",
    "    # Add shading for star and torus\n",
    "    shade = 0.3\n",
    "    r_star = df_50.loc[df_50.index[0], \"rstar/ro\"]\n",
    "    ax.fill_between(theta, 0, float(r_star.strip()), color='green', alpha=shade, label='Star')\n",
    "    r_minus = df_50.loc[df_50.index[0], \"r-/ro\"]\n",
    "    r_plus = df_50.loc[df_50.index[0], \"r+/ro\"]\n",
    "    ax.fill_between(theta, float(r_minus.strip()), float(r_plus.strip()), color='orange', alpha=shade, label='Disk')\n",
    "\n",
    "    # Add a single point for the legend\n",
    "    ax.scatter([], [], color='red', label=\"Phase W\")\n",
    "    ax.scatter([], [], color='blue', label=\"Phase Pert\")\n",
    "\n",
    "    # Plot rho_o\n",
    "    r = np.ones_like(theta)  # Constant radius at 1\n",
    "    ax.plot(theta, r, color='black', label=r\"$\\rho_{o}$\", linestyle=\":\")  # Dashed black circle\n",
    "\n",
    "    # Plot R_co\n",
    "    r_star = df_50.loc[df_50.index[0], \"Rco/ro\"]\n",
    "    r_star = np.full_like(theta, r_star)\n",
    "    ax.plot(theta, r_star, color='mediumorchid', label=r\"$r_{co}$\", linestyle=\"--\")  # Dashed black circle\n",
    "\n",
    "    # # Plot hard boundary lines\n",
    "    # for boundary in [\"rstar/ro\", \"r-/ro\", \"r+/ro\"]:\n",
    "    #     value = df_50.loc[df_50.index[0], boundary]  # Assuming row index is 0\n",
    "    #     plot_value = np.full(len(theta), float(value.strip()))\n",
    "    #     ax.plot(theta, plot_value, color='dimgrey', label=None)\n",
    "\n",
    "    # Loop for actual data points (without labels)\n",
    "    S= 10\n",
    "    for col in phase_W_df.columns:\n",
    "        if col != 'rnorm(j)':\n",
    "            phase_W_df[col] = np.radians(phase_W_df[col])\n",
    "            ax.scatter(phase_W_df[col], phase_W_df['rnorm(j)'], alpha=0.6, s=S, color='red', label=None)\n",
    "\n",
    "    for col in phase_pert_df.columns:\n",
    "        if col != 'rnorm(j)':\n",
    "            phase_pert_df[col] = np.radians(phase_pert_df[col])\n",
    "            ax.scatter(phase_pert_df[col], phase_pert_df['rnorm(j)'], alpha=0.6, s=S, color='blue', label=None)\n",
    "\n",
    "    # # Adding labels and title\n",
    "    # plt.xlabel('MIRP')\n",
    "    # plt.ylabel(r'log($\\omega$ Amplitude)')\n",
    "    \n",
    "    plt.title('Phase Plots for perterbation and |W|')\n",
    "\n",
    "    # Displaying the legend outside of the plot\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), borderaxespad=0.1)\n",
    "\n",
    "        # Save the figure before displaying\n",
    "    if save_graph:\n",
    "        save_path = target_folder / f\"Phase_Plots_{target_folder.name}.png\"\n",
    "        plt.savefig(save_path, dpi=600, bbox_inches='tight')\n",
    "\n",
    "    # Show the plot\n",
    "    if view_graph:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close()\n",
    "    return(phase_pert_df, phase_W_df)\n",
    "\n",
    "def Deploy_Phase_Plot(view_graph, save_graph):\n",
    "    # Path for models to be plotted (settled models only)\n",
    "    settled_models_path = Path(\"..\", \"Data_Galactic_Formation\", \"Models\", \"Settled_Models\").resolve()\n",
    "\n",
    "    # For loop that deploys plotting the phase of the perterbation and W\n",
    "    for target_folder in settled_models_path.iterdir():\n",
    "        # Verify only directories are targeted\n",
    "        if not target_folder.is_dir():\n",
    "            continue  # Skip if not a directory\n",
    "\n",
    "        # Verify target model contains required files fort.22 & fort.23\n",
    "        if not (target_folder / \"fort.53\").exists() or not (target_folder / \"fort.63\").exists():\n",
    "            print(f\"Warning: {target_folder.name} is missing fort.53 or fort.63\")\n",
    "            continue  # Skip this folder if fort.22 or fort.23 is missing\n",
    "      \n",
    "        # Assuming target_folder is a Path object\n",
    "        target_name = target_folder.name\n",
    "\n",
    "        js_value = re.search(r\"js(\\d+)\", target_name)\n",
    "        jin_value = re.search(r\"jin(\\d+)\", target_name)\n",
    "        jout_value = re.search(r\"jout(\\d+)\", target_name)\n",
    "        m_value = re.search(r\"m(\\d+)\", target_name)\n",
    "\n",
    "\n",
    "        js_number = int(js_value.group(1)) if js_value else None\n",
    "        jin_number = int(jin_value.group(1)) if jin_value else None\n",
    "        jout_number = int(jout_value.group(1)) if jout_value else None\n",
    "        m_number = int(m_value.group(1)) if m_value else None\n",
    "\n",
    "        print(f\"m: {m_number}, js: {js_number}, jin: {jin_number}, jout: {jout_number}\")\n",
    "\n",
    "        # Deploy and Sort models based on Global Growth Rate test results\n",
    "        Plot_of_Phases = Phase_Plot(target_folder, m_val=m_number, j_s=js_number, j_in=jin_number, j_out=jout_number, save_graph=save_graph, view_graph=view_graph)\n",
    "        \n",
    "        # return(Plot_of_Phases)\n",
    "\n",
    "# # Test Deployt_Phase_Plot for all settled\n",
    "# Deploy_Phase_Plot(view_graph=True, save_graph=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
